{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cf02ea4",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7686afd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GroundSLASH\n",
    "from ground_slash.program import Program, Choice\n",
    "from ground_slash.grounding import Grounder\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# PyTorch Geometric\n",
    "import torch_geometric\n",
    "from torch_geometric.data import HeteroData, Data, Batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37e1d04",
   "metadata": {},
   "source": [
    "### Initialize CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291f18db",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4c0674",
   "metadata": {},
   "source": [
    "# Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a955fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = list(range(10))\n",
    "n_out = len(digits)\n",
    "\n",
    "prog_str = fr'''\n",
    "img(i1). img(i2).\n",
    "\n",
    "#npp(digit(X), {digits}) :- img(X).\n",
    "\n",
    "addition(A,B,N1+N2):- digit(A,N1), digit(B,N2), A<B.\n",
    "addition(B,A,N) :- addition(A,B,N), A<B.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efd2d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from asn.asn import ASN\n",
    "\n",
    "asn =ASN.from_string(prog_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349588d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(str(asn.prog))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7b3a3d",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36409782",
   "metadata": {},
   "outputs": [],
   "source": [
    "from asn.data.datasets.mnist_addition import MNISTAddition\n",
    "import torchvision.transforms as tf\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "# MNIST addition dataset\n",
    "mnist_add = MNISTAddition(\n",
    "    n=2,\n",
    "    root=\"../data/\",\n",
    "    train=True,\n",
    "    transform=tf.Compose([tf.ToTensor(), tf.Normalize((0.1307,), (0.3081, ))]), \n",
    "    download=True,\n",
    "    digits=digits,\n",
    "    seed=1234,\n",
    ")\n",
    "# original MNIST dataset\n",
    "mnist_train = mnist_add.mnist\n",
    "mnist_test = MNIST(\n",
    "    root=\"../data/\",\n",
    "    train=False,\n",
    "    transform=tf.Compose([tf.ToTensor(), tf.Normalize((0.1307,), (0.3081, ))]),\n",
    "    download=True,\n",
    ")\n",
    "\n",
    "print(len(mnist_train))\n",
    "print(len(mnist_test))\n",
    "print(len(mnist_add))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea301437",
   "metadata": {},
   "source": [
    "# NPP configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b70967",
   "metadata": {},
   "outputs": [],
   "source": [
    "from asn.models.alexnet import AlexNet\n",
    "\n",
    "# create NPP model for digits\n",
    "model = AlexNet(n_out)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f6a4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from asn.solver import NPPContext\n",
    "\n",
    "# provide models and optimizers for NPPs\n",
    "# NOTE: only track optimizer for first digit since they share the same network (do not want multiple updates)\n",
    "asn.configure_NPPs({\n",
    "    npp_rule: {\n",
    "        \"model\": model,\n",
    "        \"optimizer\": optim.Adam(model.parameters(), lr=0.005) if not i else None\n",
    "    }\n",
    "    for i, npp_rule in enumerate(asn.rg.npp_edges)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207efd22",
   "metadata": {},
   "source": [
    "# Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae8498b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "eval_batch_size = 10000\n",
    "train_batch_size = 512\n",
    "\n",
    "# data loader for single MNIST digits\n",
    "mnist_test_loader = DataLoader(mnist_test, batch_size=eval_batch_size)\n",
    "mnist_train_loader = DataLoader(mnist_train, batch_size=eval_batch_size, shuffle=True)\n",
    "# data loader for MNIST addition\n",
    "mnist_addition_loader = DataLoader(mnist_add, batch_size=train_batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de20fd1",
   "metadata": {},
   "source": [
    "# Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f13ad5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_loader(model: nn.Module, loader: DataLoader):\n",
    "\n",
    "    n_correct = 0\n",
    "    n_total = 0\n",
    "\n",
    "    for i, (x, y) in enumerate(loader):\n",
    "\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            y_pred = torch.argmax(model(x), dim=-1)\n",
    "            n_correct += (y_pred == y).sum()\n",
    "            n_total += len(y)\n",
    "\n",
    "    return f\"{n_correct}/{n_total}\\t({float(n_correct)/n_total})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5eab3b9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "from copy import deepcopy\n",
    "from asn.solver import SolvingContext\n",
    "\n",
    "# number of epochs\n",
    "n_epochs = 10\n",
    "\n",
    "print(f\"0/{n_epochs}\\t\", \"\\t\", eval_loader(model, mnist_test_loader), eval_loader(model, mnist_train_loader))\n",
    "\n",
    "epoch_times = []\n",
    "\n",
    "for e in range(n_epochs):\n",
    "\n",
    "    ts = perf_counter()\n",
    "    \n",
    "    # running loss for epoch\n",
    "    total_loss = torch.tensor(0.0, device=device)\n",
    "    \n",
    "    # for each batch\n",
    "    for x, y in mnist_addition_loader:\n",
    "\n",
    "        # NPP forward pass\n",
    "        npp_ctx_dict = asn.npp_forward(\n",
    "            npp_data={\n",
    "                npp_rule: (x_i.to(device),)\n",
    "                for i, (npp_rule, x_i) in enumerate(zip(asn.rg.npp_edges, x))\n",
    "            },\n",
    "        )\n",
    "\n",
    "        # initialize solving context\n",
    "        solving_ctx = SolvingContext(\n",
    "            len(y),\n",
    "            npp_ctx_dict,\n",
    "        )\n",
    "        \n",
    "        # prepare data graph\n",
    "        graph_block = asn.prepare_block(\n",
    "            queries=mnist_add.to_queries(y),\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "        # solve\n",
    "        graph_block = asn.solve(graph_block)\n",
    "\n",
    "        # update stable models\n",
    "        solving_ctx.update_SMs(graph_block)\n",
    "\n",
    "        # compute loss and gradients\n",
    "        loss = solving_ctx.npp_loss\n",
    "\n",
    "        # add loss to running loss\n",
    "        total_loss += loss.detach()\n",
    "\n",
    "        # zero gradients\n",
    "        asn.zero_grad()\n",
    "\n",
    "        # backward pass\n",
    "        (-loss).backward()\n",
    "\n",
    "        # update NPPs\n",
    "        asn.step()\n",
    "\n",
    "    epoch_time = perf_counter()-ts\n",
    "    epoch_times.append(epoch_time)\n",
    "\n",
    "    # evaluate\n",
    "    print(f\"{e+1}/{n_epochs} ({epoch_time})\", total_loss, \"\\t\", eval_loader(model, mnist_test_loader), eval_loader(model, mnist_train_loader))\n",
    "\n",
    "print(f\"Average time per epoch: {sum(epoch_times)/n_epochs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebb4637",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
